# Module 2 - Linguistics

> Learn the art of communicating with AI through prompt engineering.

# 🧑‍🍳 Module Intro

This module bridges the gap between raw LLM capabilities and practical applications.

# 🖼️ Big Picture
_an image will be inserted here._

# 🔮 Learning Outcomes

* Understand how system and user prompts shape LLM behavior and responses
* Learn prompt engineering techniques for educational use cases
* Explore version-controlled prompt templates using Git as a registry
* Practice deploying and configuring Canopy AI with custom prompts

# 🔨 Tools used in this module

* Prompt Playground - Interactive Gradio interface for experimenting with prompt engineering
* Git-based Prompt Registry - Version-controlled system for managing and deploying prompt templates
* OpenShift Deployment Tools - Platform tools for configuring and running Canopy AI instances

