# Module 12 - Fine-Tuning

> Your prompt is 800 tokens long and gets sent with every single message. That's 8 million tokens a day just for instructions. What if you could bake those instructions into the model itself? ğŸ“

# ğŸ§‘â€ğŸ³ Module Intro

You've optimized Canopy's model for speed and cost. But there's one efficiency you haven't tackled yet: **the prompt itself**.

Every time a student asks a question, you send the same massive system prompt explaining how to be a Socratic tutor. Don't give answers directly. Ask guiding questions. Praise effort. Handle frustration. The prompt worksâ€”but it's expensive, slow, and students have figured out how to jailbreak it.

This module is about teaching the model to *be* a Socratic tutor, not just *pretend* to be one. You'll learn about synthetic data generation, LoRA adapters, and the fine-tuning workflow.

**The big question:** *Can we bake behavior into the model instead of describing it every time?*

# ğŸ–¼ï¸ Big Picture

![big-picture-fine-tuning.png](./images/big-picture-fine-tuning.png)
<!-- ```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FINE-TUNING PIPELINE                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚   Source     â”‚     â”‚   Synthetic  â”‚     â”‚   Training   â”‚                â”‚
â”‚  â”‚   Documents  â”‚â”€â”€â”€â”€â–ºâ”‚     Data     â”‚â”€â”€â”€â”€â–ºâ”‚   Dataset    â”‚                â”‚
â”‚  â”‚  (Docling)   â”‚     â”‚  (SDG Hub)   â”‚     â”‚   (JSONL)    â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                                   â”‚                         â”‚
â”‚                                                   â–¼                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚   Deploy     â”‚     â”‚   Evaluate   â”‚     â”‚    Train     â”‚                â”‚
â”‚  â”‚   Canopy     â”‚â—„â”€â”€â”€â”€â”‚    Model     â”‚â—„â”€â”€â”€â”€â”‚    LoRA      â”‚                â”‚
â”‚  â”‚  + Adapter   â”‚     â”‚  (lm_eval)   â”‚     â”‚(Training Hub)â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
``` -->

# ğŸ”® Learning Outcomes

By the end of this module, you'll be able to:

* **Understand when to fine-tune** â€” Know when prompt engineering hits its limits
* **Explain synthetic data generation** â€” How SDG Hub creates training examples from documents
* **Describe training datasets** â€” What format models expect and why
* **Understand LoRA** â€” How adapters enable efficient fine-tuning
* **Know evaluation approaches** â€” How to verify a fine-tuned model learned the behavior
* **Plan production deployment** â€” How to serve LoRA adapters alongside base models

# ğŸ”¨ Tools used in this module

| Tool | What It Does |
|------|--------------|
| **Docling** | Converts PDFs, slides, and documents into clean markdown for processing |
| **SDG Hub** | Generates synthetic training data using LLM-powered pipelines |
| **Training Hub** | Runs LoRA fine-tuning with optimized backends (Unsloth) |
| **lm-evaluation-harness** | Benchmarks your fine-tuned model against the baseline |
| **vLLM** | Serves LoRA adapters dynamically alongside base models |
| **Argo CD** | Deploys your fine-tuned model through GitOps |
